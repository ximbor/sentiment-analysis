name: model-deploy

on:
  schedule:
  - cron: '0 3 * * 1'
  
  workflow_dispatch:
    inputs:
      dataset_train_size:
        description: 'Number of training samples (0 for all)'
        required: false
        default: '0'
      dataset_test_size:
        description: 'Number of testing samples (0 for all)'
        required: false
        default: '0'
      learning_rate:
        description: 'Learning rate (e.g., 2e-5)'
        required: false
        default: '2e-5'
      train_epochs:
        description: 'Number of training epochs'
        required: false
        default: '3'

jobs:
  train_and_validate:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout Code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install transformers[torch] datasets scikit-learn pandas

    - name: Run Retraining and Validation
      env:
        DATASET_TRAIN_SIZE: ${{ github.event.inputs.dataset_train_size || '0' }}
        DATASET_TEST_SIZE: ${{ github.event.inputs.dataset_test_size || '0' }}
        LEARNING_RATE: ${{ github.event.inputs.learning_rate || '2e-5' }}
        TRAIN_EPOCHS: ${{ github.event.inputs.train_epochs || '3' }}
      run: python scripts/retrain.py

    - name: Install test dependencies
      run: |
        pip install pytest pytest-asyncio httpx pydantic uvicorn fastapi

    - name: Run tests
      env:
        PYTHONPATH: .
        MODEL_NAME: "./tmp_model"
      run: |
        pytest -v -s tests/test_main.py

    - name: Upload Model Artifact
      uses: actions/upload-artifact@v4
      with:
        name: trained-model-files
        path: tmp_model/
        retention-days: 1

  deploy:
    needs: train_and_validate
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - name: Checkout Code
      uses: actions/checkout@v3

    - name: Download Model Artifact
      uses: actions/download-artifact@v4
      with:
        name: trained-model-files
        path: tmp_model/

    - name: Install HF Hub
      run: pip install huggingface_hub

    - name: Push to HuggingFace Spaces/Hub
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        python -c "
        from huggingface_hub import HfApi
        api = HfApi()
        api.upload_folder(
            folder_path='./tmp_model',
            repo_id='ximbor/sentiment-monitor',
            repo_type='model',
            token='${{ secrets.HF_TOKEN }}'
        )"
